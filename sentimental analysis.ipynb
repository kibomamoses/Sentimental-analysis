{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moses Kiboma Movie Review Sentimental analysis\n",
    "\n",
    "\n",
    "Steps  used \n",
    "\n",
    "Here are the steps we will follow: \n",
    "\n",
    "1. Get the dataset<br/>\n",
    "2. Preprocessing the Data<br/>\n",
    "3. Build the Model<br/>\n",
    "4. Train the model<br/>\n",
    "5. Test the Model<br/>\n",
    "6. Predict Something<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Flatten, Dropout, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Users\\kibom\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kibom\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset using keras datasets\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data()\n",
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "y = np.concatenate((y_train, y_test), axis=0)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words have been replaced by integers that indicate the absolute popularity of the word in the dataset. The sentences in each review are therefore comprised of a sequence of integers.\n",
    "\n",
    "Let's take a quick look at a few aspects of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size \n",
      "Reviews: 50000\n",
      "Labels: 50000\n"
     ]
    }
   ],
   "source": [
    "# Dataset size\n",
    "print(\"Dataset size \")\n",
    "print(f'Reviews: {X.shape[0]}')\n",
    "print(f'Labels: {y.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 50000 reviews with their corresponding labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: \n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# Number of classes\n",
    "print(\"Classes: \")\n",
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label is represented as an integer, 0 for negative, 1 for positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: \n",
      "88585\n"
     ]
    }
   ],
   "source": [
    "# Total number of unique words\n",
    "print(\"Number of unique words: \")\n",
    "print(len(np.unique(np.hstack(X))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire dataset contains nearly 90000 words. As the integers that have replaced the words are in order of popularity, we will be able to cut down considerably on the number of words on which we train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length: \n",
      "Mean 234.76 \n",
      "Standard deviation 172.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kibom\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Review lengths\n",
    "print(\"Review length: \")\n",
    "result = [len(x) for x in X]\n",
    "result_mean = np.mean(result)\n",
    "result_std = np.std(result)\n",
    "print(f'Mean {result_mean:.2f} \\nStandard deviation {result_std:.2f}')\n",
    "\n",
    "# Plot review lengths\n",
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.distplot(result, color=\"dodgerblue\")\n",
    "plt.title('Review Length Distribution', fontsize=14)\n",
    "plt.xlabel('Words', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average length for the reviews are 235 words long. As we can see from the distribution graph, most of the reviews fall under the 500 word length. In order to get a good sense of the reviews from the dataset as a whole, we will set our standard review length to 500 words.\n",
    "\n",
    "### 2. Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Users\\kibom\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\kibom\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "## Preprocess the data\n",
    "\n",
    "# load the dataset but only keep the top 5000 words\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words,\n",
    "                                                      skip_top=50, # Skip the top 50 common words (e.g. 'the', 'is', 'and')\n",
    "                                                      seed=113,\n",
    "                                                      start_char=1,\n",
    "                                                      oov_char=2)\n",
    "\n",
    "# Use pad_sequences to pad or truncate reviews to 500 words\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build the Model\n",
    "\n",
    "Word embedding is a technique where words are encoded as real-valued vectors in a high-dimensional space, where the similarity between words in terms of meaning translates to closeness in the vector space. Keras provides a convenient way to convert positive integer representations of words into a word embedding by an Embedding layer.\n",
    "\n",
    "We will create a Recurrent Neural Network model using LSTM (Long Short-Term Memory) layers, and then a dense hidden layer of 250 neurons. The output layer has one neuron and will use a sigmoid activation to output values of 0 and 1 as predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 500, 64)           16640     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 250)               8000250   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 8,177,141\n",
      "Trainable params: 8,177,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add layers\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the model\n",
    "\n",
    "We will use a 80/20 split for training and validation on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "157/157 [==============================] - 507s 3s/step - loss: 0.4784 - accuracy: 0.7416 - val_loss: 0.2970 - val_accuracy: 0.8786\n",
      "Epoch 2/5\n",
      "157/157 [==============================] - 503s 3s/step - loss: 0.2307 - accuracy: 0.9104 - val_loss: 0.3079 - val_accuracy: 0.8756\n",
      "Epoch 3/5\n",
      "157/157 [==============================] - 536s 3s/step - loss: 0.1680 - accuracy: 0.9376 - val_loss: 0.3089 - val_accuracy: 0.8816\n",
      "Epoch 4/5\n",
      "157/157 [==============================] - 489s 3s/step - loss: 0.1116 - accuracy: 0.9615 - val_loss: 0.3942 - val_accuracy: 0.8724\n",
      "Epoch 5/5\n",
      "157/157 [==============================] - 496s 3s/step - loss: 0.0637 - accuracy: 0.9787 - val_loss: 0.4579 - val_accuracy: 0.8670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2304efbb670>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "num_epochs = 5\n",
    "batch = 128\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          validation_split=0.2, \n",
    "          epochs=num_epochs, \n",
    "          batch_size=batch, \n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test the Model\n",
    "\n",
    "We will now test the accuracy of the model by using the 25000 testing samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.68%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Accuracy: {scores[1]*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Applying the Model\n",
    "\n",
    "We will create a basic function for applying the model to predict the sentiment of any new reviews that a user may want to input to the model. The user's input will need to be put through a few Natural Language Processing steps before getting to the model in order for the correct input format to be achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for NLP steps\n",
    "stop_words = set(stopwords.words('english')) \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    clean = re.sub(r'[^\\w\\s]','',text, re.UNICODE)\n",
    "    clean = clean.lower()\n",
    "    clean = [lemmatizer.lemmatize(token) for token in clean.split(\" \")]\n",
    "    clean = [lemmatizer.lemmatize(token, \"v\") for token in clean]\n",
    "    clean = [word for word in clean if not word in stop_words]\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to replace the words with integers using the same imdb index\n",
    "def word_integers(text):\n",
    "    word_index = imdb.get_word_index()\n",
    "    ints = []\n",
    "    for i in text:\n",
    "        try:\n",
    "            word = word_index[i]\n",
    "            if word > top_words: # If the word is outside of our 10000 word vocabulary, it will be ignored\n",
    "                ints.append(2)\n",
    "            else:\n",
    "                ints.append(word_index[i])\n",
    "        except KeyError:\n",
    "            ints.append(2) # If the word is unrecognisable, like an unusual name, it will be ignored\n",
    "            continue\n",
    "    ints = np.array([ints,[]]) # Extra empty list added to create an array of lists, will be remove in a later step\n",
    "    return ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to use pad_sequences to achieve the correct input length of 500 words\n",
    "def review_padding(review, max_length):\n",
    "    length = max_length\n",
    "    padded = sequence.pad_sequences(review, maxlen=length)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that takes a review as input, then predicts the sentiment as positive or negative\n",
    "def review_predict(review):\n",
    "    # Input should be in string format\n",
    "    pred = clean_text(review)\n",
    "    pred = word_integers(pred)\n",
    "    pred = review_padding(pred, max_words)\n",
    "    pred = np.delete(pred, 1 ,axis=0) # Removes the extra empty list\n",
    "    pred = model.predict(pred)\n",
    "    if pred > 0.5:\n",
    "        result = f'Positive Review {pred[0].round(2)}'\n",
    "    else:\n",
    "        result = f'Negative Review {pred[0].round(2)}'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input - 10 star and 1 star user reviews for the film The Invisible Man (2020) from imdb.com\n",
    "good_review = \"In your average horror movie I am continuously scanning the background, but in Leigh Whannell's adaptation of The Invisible Man the horror is right behind you. You just cannot see it. The film is part of the Universal Dark Universe franchise, but reimagined by Leigh. Elisabeth Moss creeps around the gorgeous house, great production design by Alex Holmes, we are led to believe she has drugged her wealthy boyfriend Adrian played by Emerald City's Lucas; Oliver Jackson-Cohen. And in those few moments you could cut the tension with a knife. Barely escaping from this gilded prison with her sister's help, Cecilia finds refuge with her friend James and his daughter Sydney, but always feels someone is watching her. Attempting to beat her agoraphobia she eventually makes it out of the door to the mail box. A small victory. But when Adrian commits suicide, Cecilia's fears are over. With her and Harriet Dyer's sister Emily both amazed when he leaves $5 million to Cecilia, with a few unlikely codicils. But Adrian's lawyer Tom, his own brother, played by For All Mankind's Michael Dorman, assures her everything is fine. And it is. Using Adrian's $10,000 a month will allowance Cecilia sets up a Parsons College fund for Sydney, Storm Reid playing thecool daughter of Aldis Hodge's policeman James. And Cecelia feeling confident enough to work again, but why are her architectural drawings suddenly gone from her case during her interview?, and why is Diazepam suddenly on the bathroom counter?, the same medicine she used to drug Adrian, as she passes out. The hospital results show she had high levels of the Diazepam in her blood. She never took the pills. But Cecilia starts to wonder what if tech billionaire Adrian isn't actually dead, what if he created a way to make himself invisible? Could the man who abused her while he was alive, still be psychologically, and worse, terrorising her in his 'death'? We can see the duvet slipping off the bed, we know someone's there, as the photo is taken, but we cannot see him. Maybe just a foot outline on a sheet. I don't know HG Wells's The Invisible Man, other than there was a series with David McCallum when I was a kid. But Leigh Whannell has created a monster who question's Cecilia's sanity and in a shocking OMG moment ultimately robs her of her family. If no one can see her tormentor, then no one can help. But Cecilia has survived worse when living with Adrian, the painful admitting to James and Emily of the awful life she had is heartbreaking. Apparently self harm scenes were cut from the UK version which would have showed even more the psychological harm he caused her. And I cannot think of a better actress to play Cecilia than Elisabeth Moss, we are willing to invest in her as the abused woman who takes the fight to her abuser. With Tom offering Cecilia a menacing option we're totally up for it. Especially as Cecilia has an ace up her sleeve in this chilling sci-fi thriller. A terrific script and big success for Blumhouse. They are really having a moment with three of their films currently in cinemas. With an impressive score by Benjamin Wallfisch and haunting cinematography by Stefan Duscio that together builds up the suspense. As a horror fan this was superb from Leigh Whannell. The loft scenes were fantastic but it isn't relying only on the jumpy moments. Far too sophisticated a piece of work for that. Well done to the cast and crew.\"\n",
    "bad_review = \"You knew this movie would be horrible as soon as you see the opening credits CGI-ed into the water... HORRIBLE. CinemaSins is going to destroy this thing. Invisible plot holes. Invisible acting skills. Invisible suspense... invisible bank account after everything is done. The main actress (Elisabeth Moss) is seriously a horrible actress. Horrible. And she distracts you from being able to focus on the movie. She overacts every single thing. If she jumps from a sound she exaggerates it by 10x. If she looks over her shoulder to see if someone is following her she exaggerates it by 10x. I honestly am having a hard time even watching her face because it is so ugh. From the first scene the exposition is that of a first-year film student. How do you know she drugged him? She picks up the bottle of pills and shows it to you. But that isn't enough... no no, she also needs to pick up the glass of water and swirl it so you know it is in the bottle. Then she needs to say his name out loud so that he doesn't move. Then she needs to read the bottle again. Over and over. Why is this dude's research lab connected to the garage? Because the movie needs it to be. How did the dog get into the garage? Because the movie needs him there. Why in God's name did the sister stop the car to pick up the main character and then just sit there and not move?? She saw the man running towards the window and just sat there. You know she already knew that her sister was being abused, but she acted like she did not understand why she was picking up her sister in the woods in the middle of the night. Then she continued to sit there while the guy busted out the window like Superman. Am I spoiling the movie? NOPE. Why? Because all of this is in the trailer. Watch the trailer and you will know how horrible this movie is, because the trailer shows every single thing that happens in a linear fashion. Who greenlit this crap???? This movie is the reason why you do not let the director of Insidious 3 write a screenplay for a 100 year old franchise and then direct it, like he has free reign to do whatever tf he wants. I'm sorry, but they need to bring Harvey Weinstein back to Hollywood because the crap that is being churned out is WACK.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\kibom/nltk_data'\n    - 'C:\\\\Users\\\\kibom\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\kibom\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\kibom\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\kibom\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\kibom/nltk_data'\n    - 'C:\\\\Users\\\\kibom\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\kibom\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\kibom\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\kibom\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4840/2720233627.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Run the predictions and print the results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgood\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreview_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgood_review\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mbad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreview_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbad_review\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Prediction for a 10 star review: {good}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Prediction for a 1 star review: {bad}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4840/54666837.py\u001b[0m in \u001b[0;36mreview_predict\u001b[1;34m(review)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mreview_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Input should be in string format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_integers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreview_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4840/2382355853.py\u001b[0m in \u001b[0;36mclean_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mclean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'[^\\w\\s]'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNICODE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mclean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mclean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mclean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"v\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclean\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mclean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclean\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4840/2382355853.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mclean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'[^\\w\\s]'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNICODE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mclean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mclean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mclean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"v\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclean\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mclean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclean\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mlemmas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\kibom/nltk_data'\n    - 'C:\\\\Users\\\\kibom\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\kibom\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\kibom\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\kibom\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Run the predictions and print the results\n",
    "good = review_predict(good_review)\n",
    "bad = review_predict(bad_review)\n",
    "print(f'Prediction for a 10 star review: {good}')\n",
    "print(f'Prediction for a 1 star review: {bad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model has successfully predicted the sentiment of these 2 film reviews. A user would be able to input their own review and see how the model predicts the sentiment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
